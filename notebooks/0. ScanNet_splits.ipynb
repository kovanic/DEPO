{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51fda137-a8a9-4aab-939e-e9200ce1cb93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2201c2f9-25d4-4461-b802-761f2aeb5cd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import gdown\n",
    "# gdown.download(id='1viGXAYR5672DWm-iit1N90s6Uxwxj6qm')  #archive with indicies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c3430500-7a3b-4255-9e66-51078ff5778c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scannet indicies\n",
    "## intrinsics.npz: (9, ) array for each scene (but in dataset they also exist)\n",
    "## statistics.json: number of pairs? for 'train', 'val' \n",
    "## scene_data\n",
    "### train_list: train-val sequences names\n",
    "### train:  seq.npz: ['name']: array(N, 4) [space_id, scan_id, image1_id, image2_id] ['score']: array(N, )\n",
    "### val:  seq.npz: array(N, 4) [space_id, scan_id, image1_id, image2_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7bed64ec-8bd7-4848-81e7-9ba49fd34724",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e8d56a5-5914-4db8-a3e2-429e1e51ff77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from queue import PriorityQueue\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bccdfc0-4365-4d56-a1c1-c52d1bc25a45",
   "metadata": {},
   "source": [
    "# V1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05ff65a-02b8-48fa-bebb-f13dd2ddf63b",
   "metadata": {},
   "source": [
    "### Train subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "id": "a49178ba-afce-4004-867a-7242a9909575",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1513/1513 [00:51<00:00, 29.34it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "train_indicies_path = '../../ScanNet/scannet_indices/scene_data/train/'\n",
    "r_compression = 1 / 2200\n",
    "\n",
    "subset_train_indicies = None\n",
    "\n",
    "for scene_npz in tqdm(os.listdir(train_indicies_path)):\n",
    "    scene_data = np.load(train_indicies_path + scene_npz)\n",
    "    \n",
    "    covisibility_criteria = (scene_data['score'] >= 0.4) & (scene_data['score'] <= 0.8)\n",
    "    scene_pairs = scene_data['name'][covisibility_criteria, :]\n",
    "    scene_scores = scene_data['score'][covisibility_criteria]\n",
    "    n_of_pairs = scene_pairs.shape[0]\n",
    "        \n",
    "    n_to_choose = int(n_of_pairs * r_compression)\n",
    "    pairs_to_keep = np.random.choice(np.arange(n_of_pairs), n_to_choose, replace=False)\n",
    "    \n",
    "    if subset_train_indicies is None:\n",
    "        subset_train_indicies = scene_pairs[pairs_to_keep, :]\n",
    "        subset_train_scores = scene_scores[pairs_to_keep]\n",
    "    else:\n",
    "        subset_train_indicies = np.concatenate([subset_train_indicies, scene_pairs[pairs_to_keep, :]])\n",
    "        subset_train_scores = np.append(subset_train_scores, scene_scores[pairs_to_keep])\n",
    "        \n",
    "np.savez('/home/project/ScanNet/train_indices_subset.npz', name=subset_train_indicies, score=subset_train_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16e1284-c70d-40a9-a3b1-25741014c87c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99586"
      ]
     },
     "execution_count": 452,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset_train_indicies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca52a062-29ac-419c-a81a-42c8b2fe41ba",
   "metadata": {},
   "source": [
    "### Val subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "id": "a2dea9e0-a87f-487a-bf44-5bfff5b11ec0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1513/1513 [00:01<00:00, 1221.11it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "val_indicies_path = '../../ScanNet/scannet_indices/scene_data/val/'\n",
    "r_compression = 0.1\n",
    "\n",
    "subset_val_indicies = None\n",
    "n_total = 0\n",
    "for scene_npz in tqdm(os.listdir(val_indicies_path)):\n",
    "    scene_data = np.load(val_indicies_path + scene_npz)\n",
    "    \n",
    "    scene_pairs = scene_data['name']\n",
    "    scene_scores = scene_data['score']\n",
    "    n_of_pairs = scene_pairs.shape[0]\n",
    "    n_total += n_of_pairs\n",
    "    n_to_choose = int(n_of_pairs * r_compression)\n",
    "    pairs_to_keep = np.random.choice(np.arange(n_of_pairs), n_to_choose, replace=False)\n",
    "    \n",
    "    if subset_val_indicies is None:\n",
    "        subset_val_indicies = scene_pairs[pairs_to_keep, :]\n",
    "        subset_val_scores = scene_scores[pairs_to_keep]\n",
    "    else:\n",
    "        subset_val_indicies = np.concatenate([subset_val_indicies, scene_pairs[pairs_to_keep, :]])\n",
    "        subset_val_scores = np.append(subset_val_scores, scene_scores[pairs_to_keep])\n",
    "        \n",
    "np.savez('/home/project/ScanNet/val_indices_subset.npz', name=subset_val_indicies, score=subset_val_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "2f643633-bb65-49f1-a8e8-66a1a9656d67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42262"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(subset_val_indicies)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa88475-3a3e-49e6-86f0-60d3a86f1a46",
   "metadata": {},
   "source": [
    "### Create subset of ScanNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ecac88b-f584-402b-a6c5-227909437fa7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image_pairs_train = np.load('/home/project/ScanNet/train_indices_subset.npz')\n",
    "# image_pairs_val = np.load('/home/project/ScanNet/val_indices_subset.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5611bc4-9b23-4b14-a452-7d031f7b1aca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_indicies = np.concatenate([image_pairs_train['name'], image_pairs_val['name']], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "843977dd-eaf2-4873-91e2-de3f313bbab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(118820, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# all_indicies.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1389d59d-25fd-4abc-9058-b817d91df8a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# images = set()\n",
    "# for s in all_indicies:\n",
    "#     im1 = (s[0], s[1], s[2])\n",
    "#     im2 = (s[0], s[1], s[3]) \n",
    "#     images.update([im1, im2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9696ae9e-f7bc-4d91-9e3e-a39945420118",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 222123/222123 [1:52:33<00:00, 32.89it/s]\n"
     ]
    }
   ],
   "source": [
    "# src_path = '/home/project/data/scans/'\n",
    "# dst_path = '/home/project/data_sample/scans/'\n",
    "\n",
    "# for image in tqdm(images):\n",
    "#     scene_name = f'scene{image[0]:04d}_{image[1]:02d}/'\n",
    "#     rgb_name = f'{image[2]}.jpg'\n",
    "#     depth_name = f'{image[2]}.png'\n",
    "#     pose_name = f'{image[2]}.txt'\n",
    "    \n",
    "#     shutil.copyfile(src_path+scene_name+'color/'+rgb_name, dst_path+scene_name+'color/'+rgb_name)\n",
    "#     shutil.copyfile(src_path+scene_name+'depth/'+depth_name, dst_path+scene_name+'depth/'+depth_name)\n",
    "#     shutil.copyfile(src_path+scene_name+'pose/'+pose_name, dst_path+scene_name+'pose/'+pose_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79a7d4c-5c93-4c62-97b1-69fdd54d3dbd",
   "metadata": {},
   "source": [
    "### Allign test data with loading protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f09c5a2-a84c-4562-bf74-b9abbcff6790",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_43467/937024916.py:1: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  scannet_test_pairs = pd.read_csv('../../ScanNet/scannet_test_pairs_with_gt.txt', sep='\\s', header=None)\n"
     ]
    }
   ],
   "source": [
    "scannet_test_pairs = pd.read_csv('../../ScanNet/scannet_test_pairs_with_gt.txt', sep='\\s', header=None)\n",
    "\n",
    "scannet_test_pairs['image0_id'] = scannet_test_pairs[0].apply(lambda x: int(x.split('/')[-1].split('-')[1].split('.')[0]))\n",
    "scannet_test_pairs['image1_id'] = scannet_test_pairs[1].apply(lambda x: int(x.split('/')[-1].split('-')[1].split('.')[0]))\n",
    "scannet_test_pairs['scene_name'] = scannet_test_pairs[0].apply(lambda x: int(x.split('/')[1].split('scene')[1].split('_')[0]))\n",
    "scannet_test_pairs['scene_subname'] = scannet_test_pairs[0].apply(lambda x: int(x.split('/')[1].split('scene')[1].split('_')[1]))\n",
    "\n",
    "np.savez('test_indices.npz', name=scannet_test_pairs[['scene_name', 'scene_subname', 'image0_id', 'image1_id']].values)\n",
    "\n",
    "K_dict = {}\n",
    "for seq in scannet_test_pairs[0].apply(lambda x: x.split('/')[1]).unique():\n",
    "    K = np.loadtxt('../../ScanNet/scannet_test_1500/'+seq+'/intrinsic/intrinsic_depth.txt')[:3, :3].reshape(-1)\n",
    "    K_dict[seq] = K\n",
    "\n",
    "np.savez('intrinsics_test.npz', **K_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "878722eb-997d-4ca0-8277-fb9d16200763",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 1513/1513 [00:18<00:00, 81.84it/s]\n"
     ]
    }
   ],
   "source": [
    "n_of_train = 0\n",
    "for seq in tqdm(os.listdir(PATH_TRAIN)):\n",
    "    npz_seq = np.load(PATH_TRAIN + seq)\n",
    "    n_of_train += ((npz_seq['score'] > 0.4) & (npz_seq['score'] < 0.8)).sum() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0c3bd5a1-73ba-4b03-888f-ead0e7b519e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in train: 220.382338\n"
     ]
    }
   ],
   "source": [
    "print('Number of images in train:',  n_of_train / 10 ** 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "fcd2d635-cfc1-4b6d-96cd-954ccde1328d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 1513/1513 [00:00<00:00, 2568.41it/s]\n"
     ]
    }
   ],
   "source": [
    "n_of_val = 0\n",
    "for seq in tqdm(os.listdir(PATH_VAL)):\n",
    "    npz_seq = np.load(PATH_VAL + seq)\n",
    "    n_of_val += len(npz_seq['score']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "aaf93d69-0061-49ed-8b7c-ed54aab52ba8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images in validation: 0.429409\n"
     ]
    }
   ],
   "source": [
    "print('Number of images in validation:', n_of_val / 10 ** 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b714f8-5c61-43cc-a4b7-2184790591af",
   "metadata": {},
   "source": [
    "# V2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13613f7a-6379-4116-942f-aa7cd52f849a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Smart stratification\n",
    "\n",
    "Idea here is to keep the minimal number of image pairs from original dataset, but all images should be present in subset and stratification by covisibility level should be done.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8584026-70f6-49d2-85fe-73a8425a2a66",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d48f244539014504a2a20756e51c4735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1513 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_indicies_path = '../../ScanNet/scannet_indices/scene_data/train/'\n",
    "\n",
    "nodes = set()\n",
    "\n",
    "for scene_npz in tqdm(os.listdir(train_indicies_path)):\n",
    "    scene_data = np.load(train_indicies_path + scene_npz)\n",
    "    pairs = scene_data['name']\n",
    "    for i, pair in enumerate(pairs):   \n",
    "        node_1 = (pair[0], pair[1], pair[2])\n",
    "        node_2 = (pair[0], pair[1], pair[3])\n",
    "        nodes.update([node_1, node_2])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b752f83-dd76-4f7b-a980-245786c82236",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N of unique images: 2.42m\n"
     ]
    }
   ],
   "source": [
    "print(f'N of unique images: {len(nodes)/10 ** 6:.2f}m')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "id": "7c2e99d2-9b8b-4e70-a0a6-ff7dc90c9650",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def build_graph(pairs: np.ndarray, covisibility_scores: np.ndarray, covisibility_thresholds: np.ndarray):\n",
    "    \"\"\"\n",
    "    Returns graph in format: {'node_1': {(neighbor_11, covisibility_bin, covisibility_score), ... (neighbor_1k, covisibility_bin, covisibility_score)}, ..., 'node_n': {...}}\n",
    "    \"\"\"\n",
    "    graph = {}\n",
    "    for i, pair in enumerate(pairs):   \n",
    "        node_1 = (pair[0], pair[1], pair[2])\n",
    "        node_2 = (pair[0], pair[1], pair[3])\n",
    "        score = covisibility_scores[i]\n",
    "        bins = (score >= covisibility_thresholds[:, 0]) & (score < covisibility_thresholds[:, 1])\n",
    "        bin_ = np.argmax(bins)\n",
    "                \n",
    "        if bins.sum():\n",
    "            graph.setdefault(node_1, set()).update([(node_2, bin_, score)])\n",
    "            graph.setdefault(node_2, set()).update([(node_1, bin_, score)])\n",
    "    return graph\n",
    "    \n",
    "\n",
    "def build_queue(graph):\n",
    "    queue = PriorityQueue()\n",
    "    for root, neighbours in graph.items():\n",
    "        neighbours = list(neighbours)\n",
    "        N = len(neighbours)\n",
    "        var = sum((x[2] ** 2 for x in neighbours)) / N - (sum((x[2] for x in neighbours)) / N) ** 2\n",
    "        queue.put((var, (root, neighbours)))\n",
    "    return queue\n",
    "    \n",
    "    \n",
    "\n",
    "def smart_stratification(pairs: np.ndarray, covisibility_scores: np.ndarray,\n",
    "                         covisibility_thresholds: np.ndarray, global_distribution: np.ndarray):\n",
    "    graph = build_graph(pairs, covisibility_scores, covisibility_thresholds)\n",
    "    queue = build_queue(graph)\n",
    "        \n",
    "    keep_pairs = []\n",
    "    keep_scores = []\n",
    "    taken_nodes = set()\n",
    "    n_bins = len(global_distribution)\n",
    "    \n",
    "    \n",
    "    while not queue.empty():\n",
    "        _, (root, neighbours) = queue.get()\n",
    "        if root not in taken_nodes:\n",
    "            step_importances = dict(zip(np.argsort(-global_distribution), np.arange(n_bins)))\n",
    "            neighbours_importances = []\n",
    "            for neigh, bin_, score in neighbours:\n",
    "                if neigh in taken_nodes:\n",
    "                    neigh_importance = 0\n",
    "                else:\n",
    "                    neigh_importance = step_importances[bin_]\n",
    "                neighbours_importances.append(neigh_importance)\n",
    "                \n",
    "            choice_idx = np.random.choice(np.where(neighbours_importances == np.max(neighbours_importances))[0])\n",
    "            taken_nodes.update([root, neighbours[choice_idx][0]])\n",
    "            keep_pairs.append((root[0], root[1], root[2], neighbours[choice_idx][0][2]))\n",
    "            keep_scores.append(neighbours[choice_idx][2])\n",
    "            global_distribution[neighbours[choice_idx][1]] += 1\n",
    "            \n",
    "    return keep_pairs, keep_scores, global_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6784f2-1b49-4021-8134-5f95a95de1dd",
   "metadata": {},
   "source": [
    "### On train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "id": "c9953f56-caf2-4adf-99ec-44de2030b9fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1513/1513 [1:48:10<00:00,  4.29s/it]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "train_indicies_path = '../../ScanNet/scannet_indices/scene_data/train/'\n",
    "ts = np.linspace(0.4, 0.8, 41)\n",
    "covisibility_thresholds = np.concatenate([ts[:-1].reshape(-1, 1), ts[1:].reshape(-1, 1)], axis=1)\n",
    "global_distribution = np.zeros(40)\n",
    "\n",
    "all_pairs = []\n",
    "all_scores = []\n",
    "\n",
    "for scene_npz in tqdm(os.listdir(train_indicies_path)):\n",
    "    scene_data = np.load(train_indicies_path + scene_npz)\n",
    "    pairs, scores, global_distribution = smart_stratification(scene_data['name'], scene_data['score'], covisibility_thresholds, global_distribution)\n",
    "    all_pairs.extend(pairs)\n",
    "    all_scores.extend(scores)\n",
    "\n",
    "all_pairs = np.array(all_pairs)\n",
    "all_scores = np.array(all_scores)\n",
    "\n",
    "# np.savez('/home/project/code/data/scannet_splits/smart_sample_train.npz', name=all_pairs, score=all_scores)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ee6872f-b14e-44f7-916d-5ed605379135",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.261413\n"
     ]
    }
   ],
   "source": [
    "train = np.load('/home/project/code/data/scannet_splits/smart_sample_train.npz')\n",
    "print(len(train['name'])/10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "id": "5e063f1b-c1b7-4581-953b-4066f7e54d42",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "bins = np.argmax((all_scores[:, None] >= covisibility_thresholds[:, 0]) & (all_scores[:, None] < covisibility_thresholds[:, 1]), axis=1)\n",
    "n_in_bin = 2500\n",
    "keep_ids = np.empty(0)\n",
    "\n",
    "for bin_ in range(40):\n",
    "    ids = np.argwhere(bins == bin_).ravel()\n",
    "    keep_ids = np.append(keep_ids, np.random.choice(ids, size=n_in_bin, replace=False))\n",
    "    \n",
    "keep_ids = keep_ids.astype('int')\n",
    "pairs_subset = all_pairs[keep_ids, :]\n",
    "scores_subset = all_scores[keep_ids]\n",
    "\n",
    "np.savez('/home/project/code/data/scannet_splits/smart_sample_train_ft.npz', name=pairs_subset, score=scores_subset)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4543ad4f-d58d-41a2-890d-200096c863f2",
   "metadata": {},
   "source": [
    "### On val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "id": "d90a5443-f9ba-4b5b-9693-8a56d39c0927",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1513/1513 [00:13<00:00, 109.21it/s]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "val_indicies_path = '../../ScanNet/scannet_indices/scene_data/val/'\n",
    "ts = np.linspace(0.4, 0.8, 41)\n",
    "covisibility_thresholds = np.concatenate([ts[:-1].reshape(-1, 1), ts[1:].reshape(-1, 1)], axis=1)\n",
    "global_distribution = np.zeros(40)\n",
    "\n",
    "all_pairs = []\n",
    "all_scores = []\n",
    "\n",
    "for scene_npz in tqdm(os.listdir(val_indicies_path)):  \n",
    "    scene_data = np.load(val_indicies_path + scene_npz)\n",
    "    pairs, scores, global_distribution = smart_stratification(scene_data['name'], scene_data['score'], covisibility_thresholds, global_distribution)\n",
    "    all_scores.extend(scores)\n",
    "    all_pairs.extend(pairs)\n",
    "    \n",
    "all_pairs = np.array(all_pairs)\n",
    "all_scores = np.array(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "id": "a4f70b28-e243-4653-8bf4-264c0d9ffbbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "bins = np.argmax((all_scores[:, None] >= covisibility_thresholds[:, 0]) & (all_scores[:, None] < covisibility_thresholds[:, 1]), axis=1)\n",
    "n_in_bin = 1000\n",
    "keep_ids = np.empty(0)\n",
    "\n",
    "for bin_ in range(40):\n",
    "    ids = np.argwhere(bins == bin_).ravel()\n",
    "    keep_ids = np.append(keep_ids, np.random.choice(ids, size=n_in_bin, replace=False))\n",
    "    \n",
    "keep_ids = keep_ids.astype('int')\n",
    "pairs_subset = all_pairs[keep_ids, :]\n",
    "scores_subset = all_scores[keep_ids]\n",
    "\n",
    "np.savez('/home/project/code/data/scannet_splits/smart_sample_val.npz', name=pairs_subset, score=scores_subset)    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
